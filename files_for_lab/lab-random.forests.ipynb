{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a8ceafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d40d2a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = pd.read_csv('numerical.csv')\n",
    "categorical = pd.read_csv('categorical.csv')\n",
    "target = pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ac3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ca69e",
   "metadata": {},
   "source": [
    "# 1. Task 1\n",
    "\n",
    "Apply the Random Forests algorithm but this time only by upscaling the data to deal with the imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e86ab",
   "metadata": {},
   "source": [
    "### 1.1 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc2eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([numerical, categorical], axis = 1)\n",
    "y = target['TARGET_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce107eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df849ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train.select_dtypes(include='object').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a49695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(include='number').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77625ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c721f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat = X_test.select_dtypes(include='object').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bcd2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num = X_test.select_dtypes(include='number').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa728872",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99aadc",
   "metadata": {},
   "source": [
    "### 1.2 Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a33a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first').fit(X_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e01e5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_categorical_train = encoder.transform(X_train_cat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a37daa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_categorical_train = pd.DataFrame(encoded_categorical_train, columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bccf8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_categorical_test = encoder.transform(X_test_cat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5bc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_categorical_test = pd.DataFrame(encoded_categorical_test, columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5173e",
   "metadata": {},
   "source": [
    "### 1.3 Scaling\n",
    "\n",
    "> For the random forest we don´t have to do this. But I´m testing if this way I maximise the recall.\n",
    ">\n",
    "> It didn´t, so I won´t run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f96d8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler().fit(X_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c24c10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_numerical_train = scaler.transform(X_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45cb5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_numerical_train = pd.DataFrame(scaled_numerical_train, columns = X_train_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42656f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_numerical_test = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98d17154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_numerical_test = pd.DataFrame(scaled_numerical_test, columns = X_train_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc62599",
   "metadata": {},
   "source": [
    "### 1.4 Upscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7adf4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.concat([encoded_categorical_train, X_train_num, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b0870b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72486, 355)\n",
      "(72486, 355)\n",
      "(144972, 354)\n"
     ]
    }
   ],
   "source": [
    "category_1 = trainset[trainset['TARGET_B'] == 1].sample(len(trainset[trainset['TARGET_B'] == 0]), replace=True)\n",
    "print(category_1.shape)\n",
    "\n",
    "category_0 = trainset[trainset['TARGET_B']== 0 ]\n",
    "print(category_0.shape)\n",
    "\n",
    "trainset_new = pd.concat([category_0, category_1], axis=0)\n",
    "\n",
    "X_train = trainset_new.drop(['TARGET_B'], axis=1)\n",
    "y_train = trainset_new['TARGET_B']\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e51619",
   "metadata": {},
   "source": [
    "### 1.5 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae7af6",
   "metadata": {},
   "source": [
    "##### 1.5.1  Paramethers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e66d940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([encoded_categorical_test, X_test_num], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc2b5b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9466540900277735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    18083\n",
       "1     1000\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[18064,    19],\n",
       "       [  999,     1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "display(y_test.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ed970eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19063\n",
       "1       20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2bd17a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET_B\n",
       "0           18083\n",
       "1            1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1bbc3",
   "metadata": {},
   "source": [
    "##### 1.5.2  Paramethers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81cbdf",
   "metadata": {},
   "source": [
    "> I want to implement grid search to find the best params\n",
    ">\n",
    "> Don´t run it, it takes too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c21b8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {'max_depth': [3,5,10],\n",
    "#         'min_samples_split': [2,10,20],\n",
    "#         'min_samples_leaf': [2,10,20],\n",
    "#         'max_samples': [0.8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "81713d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()\n",
    "# grid_search = GridSearchCV(estimator = model, param_grid = grid, cv = 5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "89f0d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5c0353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7dcf2",
   "metadata": {},
   "source": [
    "> I'll use same params that we use in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6096c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6225960875203488\n",
      "0.5945082010166116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    18083\n",
       "1     1000\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[10788,  7295],\n",
       "       [  443,   557]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 49.5 s\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20,\n",
    "                             max_samples=0.8,)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "display(y_test.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b0d24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3452a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00792cba",
   "metadata": {},
   "source": [
    "# 2. Task 2\n",
    "\n",
    "Use Feature Selections that you have learned in class to decide if you want to use all of the features (Variance Threshold, RFE, PCA, etc.)\n",
    "\n",
    "> I´ll use PCa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4c701",
   "metadata": {},
   "source": [
    "### 2.1 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "00190e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = pd.read_csv('numerical.csv')\n",
    "categorical = pd.read_csv('categorical.csv')\n",
    "target = pd.read_csv('target.csv')\n",
    "\n",
    "X = pd.concat([numerical, categorical], axis = 1)\n",
    "y = target['TARGET_B']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_cat = X_train.select_dtypes(include='object').reset_index(drop=True)\n",
    "X_train_num = X_train.select_dtypes(include='number').reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "X_test_cat = X_test.select_dtypes(include='object').reset_index(drop=True)\n",
    "X_test_num = X_test.select_dtypes(include='number').reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdcc23",
   "metadata": {},
   "source": [
    "### 2.2 Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d1aef9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop='first').fit(X_train_cat)\n",
    "\n",
    "encoded_categorical_train = encoder.transform(X_train_cat).toarray()\n",
    "encoded_categorical_train = pd.DataFrame(encoded_categorical_train, columns=encoder.get_feature_names_out())\n",
    "\n",
    "encoded_categorical_test = encoder.transform(X_test_cat).toarray()\n",
    "encoded_categorical_test = pd.DataFrame(encoded_categorical_test, columns=encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7a994",
   "metadata": {},
   "source": [
    "### 2.3 Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cd4c4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_num)\n",
    "\n",
    "scaled_numerical_train = scaler.transform(X_train_num)\n",
    "scaled_numerical_train = pd.DataFrame(scaled_numerical_train, columns = X_train_num.columns)\n",
    "\n",
    "scaled_numerical_test = scaler.transform(X_test_num)\n",
    "scaled_numerical_test = pd.DataFrame(scaled_numerical_test, columns = X_train_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ea092",
   "metadata": {},
   "source": [
    "### 2.4 Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5fa6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([encoded_categorical_train, scaled_numerical_train], axis=1).reset_index(drop=True)\n",
    "X_test = pd.concat([encoded_categorical_test, scaled_numerical_test], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e6cc3",
   "metadata": {},
   "source": [
    "### 2.5 Fit and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "df1eaa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=0.9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=0.9)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=0.9)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(0.90)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26391990",
   "metadata": {},
   "source": [
    "> Would like to have enough components to capture at least 90% of the variation in the total data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bc98bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "X_train_pca = pd.DataFrame(X_train_pca).reset_index(drop=True)\n",
    "X_test_pca = pd.DataFrame(X_test_pca).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145e6c5",
   "metadata": {},
   "source": [
    "# 3. Task 3\n",
    "\n",
    "Re-run the Random Forest algorithm to determine if the Feature Selection has improved the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc18588",
   "metadata": {},
   "source": [
    "### 3.1 Upscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b1554113",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.concat([X_train_pca, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f3bcef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72486, 123)\n",
      "(72486, 123)\n",
      "(144972, 122)\n"
     ]
    }
   ],
   "source": [
    "category_1 = trainset[trainset['TARGET_B'] == 1].sample(len(trainset[trainset['TARGET_B'] == 0]), replace=True)\n",
    "print(category_1.shape)\n",
    "\n",
    "category_0 = trainset[trainset['TARGET_B']== 0 ]\n",
    "print(category_0.shape)\n",
    "\n",
    "trainset_new = pd.concat([category_0, category_1], axis=0)\n",
    "\n",
    "X_train_pca = trainset_new.drop(['TARGET_B'], axis=1)\n",
    "y_train = trainset_new['TARGET_B']\n",
    "\n",
    "print(X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9ad56b",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d8b0821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6633142951742406\n",
      "0.6643609495362365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    18083\n",
       "1     1000\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[12236,  5847],\n",
       "       [  558,   442]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 43s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20,\n",
    "                             max_samples=0.8,)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "print(clf.score(X_train_pca, y_train))\n",
    "print(clf.score(X_test_pca, y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "display(y_test.value_counts())\n",
    "display(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce162131",
   "metadata": {},
   "source": [
    "# 4. Task 4\n",
    "\n",
    "Discuss the output and its impact in the business scenario. Is the cost of a false positive equals to the cost of the false negative? How would you change your algorithm or data in order to maximize the return of the business?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e7652",
   "metadata": {},
   "source": [
    "In the one hand:\n",
    "\n",
    "    We have predicted that 5847+442 = 6289 people will make a donation.\n",
    "    However, there are 1000 people that actually made a donation.\n",
    "\n",
    "    Assuming the cost per mail is 0.65, we have lost (6289-1000)*0.65 = 3438\n",
    "\n",
    "    Precision = 442/(442+5847) = 0.07\n",
    "    Recall = 442/(442+558) = 0.44\n",
    "\n",
    "    We´d like to minimise the false positives, that means increment precision.\n",
    "    \n",
    "    So we´d like to increment precision.\n",
    "    \n",
    "In the other hand:\n",
    "\n",
    "    We didn´t send the mail to 558 potential donors. Assuming the average donation is 15, we could´ve earned 558*15 = 8370.\n",
    "    \n",
    "    We´d like to minimise the false negatives, that means increment recall.\n",
    "    \n",
    "The real benefit is 1000*(15-0.65) = 14350\n",
    "\n",
    "We obtained 442*(15-0.65) = 6343\n",
    "\n",
    "There is 8007 of difference.\n",
    "\n",
    "If we had sent the mail to 558 extra people (maximise recall), we would´ve obtained: 1000*(15-0.65) - 5847*0.65 = 10550\n",
    "With the prediction we earned: 442*15 - (5847+442)*0.65 = 6630 - 6289 = 341\n",
    "If we tried to maximise precision, we would obtained 442*15 = 6630\n",
    "\n",
    "##### So it would be better to send the mail to more people than we should than not send it to the right people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
